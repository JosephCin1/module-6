{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56119fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a41264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\AppData\\Local\\Temp\\ipykernel_12036\\2132570383.py:1: DtypeWarning: Columns (2,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Portland_Maps_Assessor_Data.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Portland_Maps_Assessor_Data.csv\")\n",
    "clean_df = df.dropna()\n",
    "clean_df.to_csv(\"cleaned_portland_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b331a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: $593,630.00 \t Predicted: $798,783.24\n",
      "Actual: $553,120.00 \t Predicted: $595,737.39\n",
      "Actual: $615,530.00 \t Predicted: $754,966.03\n",
      "Actual: $680,220.00 \t Predicted: $927,402.51\n",
      "Actual: $375,320.00 \t Predicted: $407,405.06\n",
      "Actual: $276,120.00 \t Predicted: $442,251.17\n",
      "Actual: $478,480.00 \t Predicted: $697,285.50\n",
      "Actual: $2,835,610.00 \t Predicted: $625,006.31\n",
      "Actual: $348,560.00 \t Predicted: $278,643.02\n",
      "Actual: $530,430.00 \t Predicted: $488,869.08\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_portland_data.csv\")\n",
    "\n",
    "# Filter useful columns\n",
    "features = ['square_feet', 'year_built', 'latitude', 'longitude', 'zip_code_string', 'neighborhood']\n",
    "target = 'market_value'\n",
    "\n",
    "# Drop rows with missing target or features\n",
    "df = df.dropna(subset=features + [target])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df_encoded = pd.get_dummies(df[features])\n",
    "\n",
    "# Set up input (X) and output (y)\n",
    "X = df_encoded\n",
    "y = df[target]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print predicted vs actual values\n",
    "for real, pred in zip(y_test[:10], y_pred[:10]):  # adjust [:10] to show more or fewer rows\n",
    "    print(f\"Actual: ${real:,.2f} \\t Predicted: ${pred:,.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f58a784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.copy()\n",
    "train_data[target] = y_train\n",
    "\n",
    "# Save the training data to a new CSV file\n",
    "train_data.to_csv(\"training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c052d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 Random Predictions (Portland only, no TRUNCATED addresses):\n",
      "                           address        neighborhood      city  zip_code  \\\n",
      "45839           1623 SE MALDEN ST    SELLWOOD-MORELAND  PORTLAND 97,202.00   \n",
      "204609   6616 NE KILLINGSWORTH ST                CULLY  PORTLAND 97,218.00   \n",
      "151568           4323 SE 12TH AVE             BROOKLYN  PORTLAND 97,202.00   \n",
      "166700       4915 WI/ SE 17TH AVE             BROOKLYN  PORTLAND 97,202.00   \n",
      "866      0837 SW PALATINE HILL RD         COLLINS VIEW  PORTLAND 97,219.00   \n",
      "142490           4054 SE BOISE ST   CRESTON-KENILWORTH  PORTLAND 97,202.00   \n",
      "60578            1914 NE 78TH AVE        MADISON SOUTH  PORTLAND 97,213.00   \n",
      "160005        4627 N MARYLAND AVE             OVERLOOK  PORTLAND 97,217.00   \n",
      "159721  4621-4623 N MINNESOTA AVE             OVERLOOK  PORTLAND 97,217.00   \n",
      "218686          7325 N FOWLER AVE          ARBOR LODGE  PORTLAND 97,217.00   \n",
      "\n",
      "        latitude  longitude        Actual     Predicted  \n",
      "45839      45.47    -122.65    816,800.00    939,946.30  \n",
      "204609     45.56    -122.59    469,140.00    597,288.41  \n",
      "151568     45.49    -122.65    716,770.00    847,232.00  \n",
      "166700     45.49    -122.65 11,857,930.00 10,070,479.50  \n",
      "866        45.45    -122.67  2,005,480.00  1,141,573.32  \n",
      "142490     45.49    -122.62    510,150.00    642,271.33  \n",
      "60578      45.54    -122.58    436,190.00    386,009.48  \n",
      "160005     45.56    -122.68  2,933,350.00  1,895,162.91  \n",
      "159721     45.56    -122.68    686,400.00    910,633.38  \n",
      "218686     45.58    -122.71    684,380.00    612,858.50  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the cleaned data\n",
    "df = pd.read_csv(\"cleaned_portland_data.csv\")\n",
    "\n",
    "# Filter to only include rows where city is Portland and address does not contain 'TRUNCATED'\n",
    "df = df[(df['city'].str.upper() == 'PORTLAND') & (~df['address'].str.upper().str.contains('TRUNCATED'))]\n",
    "\n",
    "# Define features and target\n",
    "features = ['square_feet', 'year_built', 'latitude', 'longitude', 'zip_code_string', 'neighborhood']\n",
    "target = 'market_value'\n",
    "\n",
    "# Drop rows with missing values in features or target\n",
    "df = df.dropna(subset=features + [target])\n",
    "\n",
    "# Remove rows where market value is 0\n",
    "df = df[df['market_value'] != 0]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_encoded = pd.get_dummies(df[features])\n",
    "y = df[target]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create error dataframe\n",
    "error = y_test - y_pred\n",
    "error_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Error': error,\n",
    "    'Abs_Error': error.abs()\n",
    "})\n",
    "\n",
    "# Filter out predictions where actual value is 0\n",
    "error_df = error_df[error_df['Actual'] != 0]\n",
    "\n",
    "# Sample 10 random rows\n",
    "sampled_errors = error_df.sample(10, random_state=1)\n",
    "\n",
    "# Get original test data (non-encoded)\n",
    "original_test_data = df.loc[X_test.index]\n",
    "sampled_rows = original_test_data.loc[sampled_errors.index]\n",
    "\n",
    "# Add Actual and Predicted values\n",
    "sampled_rows = sampled_rows.copy()\n",
    "sampled_rows['Actual'] = sampled_errors['Actual'].round(2)\n",
    "sampled_rows['Predicted'] = sampled_errors['Predicted'].round(2)\n",
    "\n",
    "# Display relevant information\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "print(\"\\n10 Random Predictions (Portland only, no TRUNCATED addresses):\")\n",
    "print(sampled_rows[['address', 'neighborhood', 'city', 'zip_code', 'latitude', 'longitude', 'Actual', 'Predicted']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "748183f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 468,373.95\n",
      "R² Score: 0.5263\n",
      "\n",
      "Top 5 samples with the largest errors:\n",
      "             Actual     Predicted        Error   Abs_Error\n",
      "344      811,370.00  1,810,768.86  -999,398.86  999,398.86\n",
      "24525          0.00    999,363.33  -999,363.33  999,363.33\n",
      "80071  1,732,330.00  2,731,444.74  -999,114.74  999,114.74\n",
      "65797    841,810.00  1,840,823.15  -999,013.15  999,013.15\n",
      "72036    476,360.00    475,361.12       998.88      998.88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Assuming you have already trained the model and have y_test (actual values) and y_pred (predicted values)\n",
    "# If you haven't defined them, you can follow the previous code to do that\n",
    "\n",
    "# Calculate the absolute error for each prediction\n",
    "error = y_test - y_pred\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics with formatted output (no scientific notation)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:,.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Create a DataFrame to examine both actual and predicted values with error\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Error': error,\n",
    "    'Abs_Error': error.abs()\n",
    "})\n",
    "\n",
    "# Format the numbers to avoid scientific notation\n",
    "comparison_df['Actual'] = comparison_df['Actual'].apply(lambda x: f\"{x:,.2f}\")\n",
    "comparison_df['Predicted'] = comparison_df['Predicted'].apply(lambda x: f\"{x:,.2f}\")\n",
    "comparison_df['Error'] = comparison_df['Error'].apply(lambda x: f\"{x:,.2f}\")\n",
    "comparison_df['Abs_Error'] = comparison_df['Abs_Error'].apply(lambda x: f\"{x:,.2f}\")\n",
    "\n",
    "# Sort by the absolute error to see where the model made the largest mistakes\n",
    "comparison_df_sorted = comparison_df.sort_values(by='Abs_Error', ascending=False)\n",
    "\n",
    "# Display the top 5 largest errors\n",
    "print(\"\\nTop 5 samples with the largest errors:\")\n",
    "print(comparison_df_sorted.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
